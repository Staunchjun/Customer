{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import sys\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "def delUnname0(df):\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def proper_model(data_ts, maxLag):\n",
    "    init_bic = sys.maxint\n",
    "    init_p = 0\n",
    "    init_q = 0\n",
    "    init_properModel = None\n",
    "    for p in np.arange(maxLag):\n",
    "        for q in np.arange(maxLag):\n",
    "            model = sm.tsa.ARMA(data_ts, order=(p, q), freq='D')\n",
    "            try:\n",
    "                results_ARMA = model.fit(disp=-1, method='css')\n",
    "            except:\n",
    "                continue\n",
    "            bic = results_ARMA.bic\n",
    "            if bic < init_bic:\n",
    "                init_p = p\n",
    "                init_q = q\n",
    "                init_properModel = results_ARMA\n",
    "                init_bic = bic\n",
    "    return init_bic, init_p, init_q, init_properModel\n",
    "\n",
    "\n",
    "def test_DF(timeseries):\n",
    "    # Perform Dickey-Fuller test:\n",
    "    print 'Results of Dickey-Fuller Test:'\n",
    "\n",
    "    a_timeseries = np.array(timeseries)\n",
    "    dim_1_data = []\n",
    "    for x in a_timeseries:\n",
    "        dim_1_data.extend(x)\n",
    "\n",
    "    dftest = adfuller(dim_1_data, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "    print dfoutput\n",
    "\n",
    "\n",
    "Customer_Flow = pd.read_csv(\"C:\\Users\\Administrator\\PycharmProjects\\Customer\\Customer_Flow.csv\")\n",
    "Customer_Flow = delUnname0(Customer_Flow)\n",
    "Customer_Flow['data'] = pd.to_datetime(Customer_Flow['data'])\n",
    "p_result = []\n",
    "errorshop = []\n",
    "for shop_id, eachShop in Customer_Flow.groupby(['shop_id']):\n",
    "    try:\n",
    "        eachShop.index = eachShop['data']\n",
    "        eachShop = eachShop.drop(['data', 'shop_id'], axis=1)\n",
    "\n",
    "        eachShop_series = pd.Series(index=eachShop.index, data=eachShop.Num)\n",
    "\n",
    "        # 数据预处理 不一定是取log,可能差分呢,也可能小波,也有可能卡尔曼傅里叶,也可以把序列进行分解然后进行拟合\n",
    "        ts_log = np.log(eachShop_series)\n",
    "        # 这里做一阶差分\n",
    "        ts_log_diff = ts_log - ts_log.shift()\n",
    "        ts_log_diff.dropna(inplace=True)\n",
    "\n",
    "        #  这里使用模型参数自动识别\n",
    "        init_bic, init_p, init_q, init_properModel = proper_model(ts_log_diff, 10)\n",
    "        print 'shop_id', shop_id, 'bic:', init_bic, 'p:', init_p, 'q:', init_q\n",
    "\n",
    "        # 预测结果还原\n",
    "        predict_ts = init_properModel.predict(start=\"2016-10-31\", end=\"2016-11-14\")\n",
    "        predict_ts_cumsum = predict_ts.cumsum()\n",
    "\n",
    "        # 把最后一个值作为基本值。或者拿14天做一个均值。作为基本值\n",
    "        base_value = sum(ts_log.ix[len(ts_log) - 14:len(ts_log) - 1]) / 14\n",
    "        #             base_value = ts_log.ix[len(ts_log)-32]\n",
    "        print \"base value is :\", base_value\n",
    "        base_value_set = []\n",
    "        for x in range(1, len(predict_ts) + 1):\n",
    "            base_value_set.append(base_value)\n",
    "\n",
    "        predictions_ARIMA_log = pd.Series(base_value_set, index=predict_ts.index)\n",
    "        predictions_ARIMA_log.rename(columns={0: 'Num'}, inplace=True)\n",
    "        predictions_ARIMA_log = predictions_ARIMA_log.add(predict_ts_cumsum)\n",
    "\n",
    "        ts_log = ts_log.ix[predictions_ARIMA_log.index]\n",
    "        rmse = np.sqrt(np.sum((predictions_ARIMA_log - ts_log) ** 2) / ts_log.size)\n",
    "        print rmse\n",
    "\n",
    "        log_recover = np.exp(predictions_ARIMA_log)\n",
    "        log_recover.dropna(inplace=True)\n",
    "        result = pd.DataFrame(log_recover)\n",
    "        result = result.rename(columns={0: 'Num'})\n",
    "        each_line = []\n",
    "        each_line.append(shop_id)\n",
    "        for x in result.Num:\n",
    "            each_line.append(x)\n",
    "        p_result.append(each_line)\n",
    "\n",
    "    except Exception, e:\n",
    "        errorshop.append(shop_id)\n",
    "        print '------------------------------ValueError:note down error shop id--------------------------'\n",
    "        continue\n",
    "print errorshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_result = abs(pd.DataFrame(p_result).astype(int))\n",
    "p_result.to_csv('ARMA_D.csv',header=False,index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}